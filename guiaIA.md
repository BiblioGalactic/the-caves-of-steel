# GuÃ­a Completa de llama.cpp - Tu IA Local en Terminal

> Una guÃ­a prÃ¡ctica para dominar el ecosistema de modelos de IA locales

---

## ðŸ§  Conceptos Fundamentales (Para empezar bien)

### Â¿QuÃ© es un archivo `.gguf`?
Es como un **archivo ZIP pero para modelos de IA**. Contiene todo lo necesario:
- La arquitectura del modelo (cÃ³mo estÃ¡ construido)
- Los pesos neuronales (el "conocimiento" entrenado)  
- El tokenizador (cÃ³mo convierte texto en nÃºmeros)
- Metadatos y configuraciÃ³n

**Por eso son portÃ¡tiles**: copias el archivo y ya tienes la IA completa.

### Â¿QuÃ© es la CuantizaciÃ³n?
Imagina una foto en 4K vs la misma foto comprimida en JPEG:
- **F16**: PrecisiÃ³n mÃ¡xima, consumo de RAM brutal
- **Q8_0**: Casi sin pÃ©rdida, 50% menos RAM  
- **Q6_K**: Excelente equilibrio calidad/tamaÃ±o
- **Q5_K_M**: Buena calidad, compacto
- **Q4_K_M**: EstÃ¡ndar recomendado para la mayorÃ­a
- **Q4_K_S**: Muy compacto, pÃ©rdida notable pero funcional

### Tokens: La "Moneda" de la IA
Los modelos no leen palabras, leen **tokens**:
- `"Hola"` = 1 token
- `"artificial"` = 2 tokens (`"art"` + `"ificial"`)
- `"ðŸ¤–"` = 1 token

**Regla prÃ¡ctica**: 1 token â‰ˆ 0.75 palabras en espaÃ±ol.

---

## ðŸŽ¯ Tipos de Modelos y Sus Especialidades

### Por Idioma y Dominio

| Especialidad | Idioma Principal | Estilo | Casos de Uso TÃ­picos |
|--------------|-----------------|--------|---------------------|
| **TÃ©cnico/AlemÃ¡n** | AlemÃ¡n | Formal, normativo | Documentos oficiales, traducciones precisas |
| **ProgramaciÃ³n** | InglÃ©s | AnÃ¡lisis estructurado | Debugging, arquitectura, code review |
| **JaponÃ©s** | JaponÃ©s | Imperativos, instrucciones | DocumentaciÃ³n tÃ©cnica japonesa |
| **Contexto Largo** | MultilingÃ¼e | Conocimiento amplio | AnÃ¡lisis complejos, investigaciÃ³n |
| **General/Balanceado** | InglÃ©s | GeneraciÃ³n fluida | Uso diario, tareas variadas |
| **MÃ©dico/ClÃ­nico** | InglÃ©s | ClÃ­nico, biomÃ©dico | Textos mÃ©dicos, farmacÃ©uticos |
| **Conversacional** | InglÃ©s | DiÃ¡logo natural | Chat, atenciÃ³n al cliente |
| **DocumentaciÃ³n** | InglÃ©s | Explicaciones suaves | Manuales, guÃ­as tÃ©cnicas |
| **Compacto/RÃ¡pido** | InglÃ©s | Razonamiento eficiente | Pruebas rÃ¡pidas, hardware limitado |
| **Multiidioma** | Chino/InglÃ©s | Contexto extenso | Documentos internacionales |
| **Ultra Ligero** | InglÃ©s | Testing rÃ¡pido | Desarrollo, IoT, experimentos |
| **Python Especializado** | InglÃ©s | Tutoriales detallados | EnseÃ±anza de programaciÃ³n |
| **AcadÃ©mico** | Chino/InglÃ©s | Papers cientÃ­ficos | InvestigaciÃ³n, textos tÃ©cnicos |
| **JurÃ­dico/Formal** | InglÃ©s | Institucional | Contratos, polÃ­ticas, compliance |
| **AutomatizaciÃ³n** | InglÃ©s | Decisiones complejas | Workflows, gestiÃ³n de procesos |
| **Base Sin Filtros** | InglÃ©s | Neutral | Experimentos, respuestas directas |
| **Narrativo** | InglÃ©s | MitolÃ³gico, storytelling | Worldbuilding, ficciÃ³n Ã©pica |
| **Creativo Expresivo** | InglÃ©s | DramÃ¡tico, emotivo | FicciÃ³n, roleplay creativo |
| **FilosÃ³fico** | InglÃ©s | DiÃ¡logo socrÃ¡tico | Debates, pensamiento crÃ­tico |
| **Sin Censura** | InglÃ©s | Temas sensibles | InvestigaciÃ³n de seguridad |
| **Roleplay Avanzado** | InglÃ©s | Narrativa libre | Roleplay, exploraciÃ³n creativa |

---

## ðŸ›  Herramientas del Ecosistema

### 1. NÃºcleo de EjecuciÃ³n

| Binario | FunciÃ³n Principal | CuÃ¡ndo Usar |
|---------|-------------------|-------------|
| `llama-cli` | **Motor principal**. Ejecuta modelos desde terminal | Scripts, automatizaciÃ³n, pruebas rÃ¡pidas |
| `llama-run` | Chat interactivo con memoria de conversaciÃ³n | Experimentar, dialogar con modelos |
| `llama-server` | Servidor web con API REST | Integrar con aplicaciones, uso remoto |

### 2. Herramientas de AnÃ¡lisis

| Herramienta | FunciÃ³n | Utilidad PrÃ¡ctica |
|-------------|---------|-------------------|
| `llama-tokenize` | Muestra cÃ³mo el modelo interpreta tu texto | Optimizar prompts, entender lÃ­mites |
| `llama-bench` | Mide rendimiento en tu hardware | Comparar modelos, optimizar configuraciÃ³n |
| `llama-embedding` | Convierte texto en vectores numÃ©ricos | BÃºsqueda semÃ¡ntica, anÃ¡lisis de similitud |

### 3. Herramientas de OptimizaciÃ³n

| Herramienta | PropÃ³sito | CuÃ¡ndo es Necesaria |
|-------------|-----------|-------------------|
| `llama-quantize` | Comprime modelos para menos RAM | Tu hardware no soporta el modelo completo |
| `llama-gguf-split` | Divide modelos en fragmentos | Descargas lentas, almacenamiento limitado |
| `llama-gguf-hash` | Verifica integridad de archivos | Asegurar descargas correctas |

---

## âš™ï¸ ParÃ¡metros Esenciales

### BÃ¡sicos (Imprescindibles)

| ParÃ¡metro | FunciÃ³n | Valores TÃ­picos | Ejemplo PrÃ¡ctico |
|-----------|---------|----------------|------------------|
| `-m` | Ruta al modelo | Ruta absoluta | `-m ~/modelos/mistral-7b.gguf` |
| `-p` | Tu prompt/pregunta | Texto libre | `-p "Explica la fotosÃ­ntesis"` |
| `-n, --n-predict` | Tokens mÃ¡ximos a generar | 128-2048 | `-n 512` (respuesta media) |
| `-c, --ctx-size` | TamaÃ±o del contexto | 512-16384 | `-c 4096` (documento largo) |

### Control de Contexto y Memoria

| ConfiguraciÃ³n | Uso de RAM Aprox. | Escenario Ideal |
|---------------|-------------------|-----------------|
| `--ctx-size 1024` | ~1-2MB | Chat bÃ¡sico, preguntas cortas |
| `--ctx-size 2048` | ~2-4MB | Conversaciones normales |
| `--ctx-size 4096` | ~4-8MB | Documentos medianos, anÃ¡lisis |
| `--ctx-size 8192` | ~8-16MB | Textos largos, investigaciÃ³n |
| `--ctx-size 16384` | ~16-32MB | Documentos muy extensos |

### Control de Creatividad

| Temperatura | Comportamiento | Casos de Uso |
|-------------|----------------|--------------|
| `--temp 0.1` | **Robot**: Muy determinista | CÃ³digo, correcciones, datos precisos |
| `--temp 0.3` | **TÃ©cnico**: Preciso pero flexible | DocumentaciÃ³n, explicaciones |
| `--temp 0.7` | **Humano**: Equilibrio natural | ConversaciÃ³n general |
| `--temp 0.9` | **Creativo**: DinÃ¡mico | Brainstorming, ideas |
| `--temp 1.2` | **Artista**: Muy experimental | FicciÃ³n, narrativa libre |

### Control de Calidad de Salida

| ParÃ¡metro | Efecto | Valor Conservador | Valor Creativo |
|-----------|--------|------------------|----------------|
| `--top-p` | Variedad de vocabulario | 0.9 | 0.95 |
| `--top-k` | LÃ­mite de opciones | 20-40 | 80-100 |
| `--repeat-penalty` | Previene repeticiones | 1.1 | 1.05 |
| `--repeat-last-n` | Ventana anti-repeticiÃ³n | 64 | 128 |

### OptimizaciÃ³n de Rendimiento

| ParÃ¡metro | FunciÃ³n | ConfiguraciÃ³n TÃ­pica |
|-----------|---------|---------------------|
| `-t, --threads` | Hilos de CPU | NÃºmero de cores disponibles |
| `--batch-size` | Procesamiento por lotes | 512-2048 (segÃºn RAM) |
| `--gpu-layers` | Capas en GPU | 99 (usar toda la GPU disponible) |

---

## ðŸ“‹ Recetas por Especialidad

### ðŸ”§ CorrecciÃ³n y EdiciÃ³n de Texto

```bash
# CorrecciÃ³n precisa de documentos
./llama-cli \
    -m ./modelos/mistral-7b-instruct.gguf \
    -p "Corrige errores ortogrÃ¡ficos y gramaticales: $(cat documento.txt)" \
    -c 4096 \
    -n 512 \
    --temp 0.2 \
    --top-p 0.9 \
    --repeat-penalty 1.1 \
    --silent
```

### ðŸ’» AnÃ¡lisis y RevisiÃ³n de CÃ³digo

```bash
# RevisiÃ³n de cÃ³digo con anÃ¡lisis detallado
./llama-cli \
    -m ./modelos/deepseek-coder.gguf \
    -p "Analiza este cÃ³digo y sugiere mejoras: $(cat script.py)" \
    -c 8192 \
    -n 1024 \
    --temp 0.1 \
    --repeat-penalty 1.1 \
    --silent
```

### ðŸŽ¨ GeneraciÃ³n Creativa

```bash
# Escritura creativa con alta expresividad
./llama-cli \
    -m ./modelos/chronos-hermes.gguf \
    -p "Escribe una historia Ã©pica sobre el despertar de una IA" \
    -c 4096 \
    -n 1500 \
    --temp 0.9 \
    --top-p 0.95 \
    --repeat-penalty 1.05
```

### ðŸ” AnÃ¡lisis de Documentos Extensos

```bash
# Procesamiento de contexto muy largo
./llama-cli \
    -m ./modelos/llama-70b.gguf \
    -p "Resume y analiza este documento completo: $(cat documento_largo.txt)" \
    -c 16384 \
    -n 2048 \
    --temp 0.5 \
    --top-p 0.9 \
    --repeat-penalty 1.1 \
    -t 8
```

### ðŸ’¬ ConversaciÃ³n Natural

```bash
# Chat interactivo con memoria
./llama-run \
    -m ./modelos/openchat.gguf \
    --repeat-penalty 1.1 \
    --temp 0.7 \
    -c 2048 \
    -i
```

---

## ðŸ§ª Estrategias por Tipo de Tarea

### Tareas TÃ©cnicas y Factuales
```bash
# ConfiguraciÃ³n para precisiÃ³n mÃ¡xima
--temp 0.1-0.3 --top-p 0.9 --repeat-penalty 1.1
# Modelos recomendados: Coder, Medical, Technical
```

### ConversaciÃ³n y Explicaciones
```bash
# ConfiguraciÃ³n balanceada y natural
--temp 0.6-0.8 --top-p 0.9 --repeat-penalty 1.1 --repeat-last-n 64
# Modelos recomendados: Chat, General-purpose, Instruction-following
```

### Creatividad y Brainstorming
```bash
# ConfiguraciÃ³n para mÃ¡xima expresividad
--temp 0.8-1.2 --top-p 0.95 --repeat-penalty 1.05
# Modelos recomendados: Creative, Storytelling, Roleplay
```

### InvestigaciÃ³n y AnÃ¡lisis
```bash
# ConfiguraciÃ³n para profundidad analÃ­tica
--temp 0.3-0.5 --top-p 0.9 -c 8192+ --n-predict 1024+
# Modelos recomendados: Large context, Academic, Research-focused
```

---

## ðŸš€ AutomatizaciÃ³n e IntegraciÃ³n

### Script de SelecciÃ³n AutomÃ¡tica de Modelo

```bash
#!/bin/bash
# Selector inteligente basado en tipo de tarea

select_model_by_task() {
    local task="$1"
    local base_path="./modelos"
    
    case "$task" in
        "code"|"programming")
            echo "$base_path/deepseek-coder.gguf"
            ;;
        "creative"|"story")
            echo "$base_path/chronos-hermes.gguf"
            ;;
        "medical"|"health")
            echo "$base_path/meditron.gguf"
            ;;
        "legal"|"formal")
            echo "$base_path/nous-hermes-legal.gguf"
            ;;
        "research"|"academic")
            echo "$base_path/llama-70b.gguf"
            ;;
        *)
            echo "$base_path/mistral-instruct.gguf"
            ;;
    esac
}

# Uso del selector
TASK_TYPE="$1"
MODELO=$(select_model_by_task "$TASK_TYPE")
PROMPT="$2"

./llama-cli -m "$MODELO" -p "$PROMPT" -c 4096 -n 512 --temp 0.7
```

### Servidor Multi-Modelo

```bash
#!/bin/bash
# Lanzar mÃºltiples modelos como servicios

start_model_server() {
    local model_path="$1"
    local port="$2"
    local model_name="$3"
    
    ./llama-server \
        -m "$model_path" \
        --host 0.0.0.0 \
        --port "$port" \
        -c 4096 \
        --gpu-layers 99 &
    
    echo "âœ… $model_name servidor iniciado en puerto $port"
}

# Iniciar servicios especializados
start_model_server "./modelos/mistral-general.gguf" 8080 "General"
start_model_server "./modelos/deepseek-coder.gguf" 8081 "CÃ³digo"
start_model_server "./modelos/creative-model.gguf" 8082 "Creativo"

echo "ðŸŒ Servidores disponibles:"
echo "  General: http://localhost:8080"
echo "  CÃ³digo: http://localhost:8081" 
echo "  Creativo: http://localhost:8082"
```

### Pipeline de Procesamiento de Documentos

```bash
#!/bin/bash
# Pipeline completo: OCR â†’ CorrecciÃ³n â†’ AnÃ¡lisis

process_document() {
    local input_image="$1"
    local output_dir="./processed"
    
    mkdir -p "$output_dir"
    
    # 1. OCR del documento
    tesseract "$input_image" "$output_dir/raw_text"
    
    # 2. CorrecciÃ³n con IA
    ./llama-cli \
        -m ./modelos/correction-model.gguf \
        -p "Corrige errores en este texto: $(cat "$output_dir/raw_text.txt")" \
        -c 4096 -n 1024 --temp 0.2 --silent \
        > "$output_dir/corrected_text.txt"
    
    # 3. AnÃ¡lisis y resumen
    ./llama-cli \
        -m ./modelos/analysis-model.gguf \
        -p "Resume los puntos clave: $(cat "$output_dir/corrected_text.txt")" \
        -c 2048 -n 256 --temp 0.5 --silent \
        > "$output_dir/summary.txt"
    
    echo "âœ… Documento procesado en $output_dir"
}

# Usar el pipeline
process_document "documento_escaneado.png"
```

---

## ðŸ›¡ SoluciÃ³n de Problemas Comunes

### Modelos Muy Grandes (70B+)
**SÃ­ntoma**: Sistema lento o sin memoria suficiente
**Soluciones**:
```bash
# Reducir uso de memoria
-c 2048              # Menos contexto
-t 4                 # Menos hilos
--gpu-layers 50      # Solo parte en GPU
# O usar cuantizaciÃ³n mÃ¡s agresiva (Q4_K_S)
```

### Modelos de CÃ³digo
**SÃ­ntoma**: Respuestas incompletas o cÃ³digo cortado
**Soluciones**:
```bash
-n 2048              # MÃ¡s tokens de salida
--temp 0.1           # MÃ¡xima precisiÃ³n
-c 8192              # MÃ¡s contexto para cÃ³digo largo
--ignore-eos         # No cortar prematuramente
```

### Modelos Creativos
**SÃ­ntoma**: RepeticiÃ³n o pÃ©rdida de coherencia
**Soluciones**:
```bash
--repeat-penalty 1.1  # Penalizar repeticiones
--mirostat 2          # Control automÃ¡tico
--temp 0.8            # No exceder temperatura
-c 4096+              # MÃ¡s contexto para coherencia
```

### DetecciÃ³n de Problemas de Rendimiento
```bash
# Monitorear uso de recursos
watch -n 1 'ps aux | grep llama-cli'

# Benchmark rÃ¡pido
./llama-bench -m modelo.gguf -p 512 -n 128

# Test de memoria
./llama-cli -m modelo.gguf -c 1024 -n 10 --temp 0.1 -p "Test"
```

---

## ðŸŽ¯ ConfiguraciÃ³n Productiva

### Variables de Entorno Ãštiles

```bash
# AÃ±adir a tu .bashrc o .zshrc
export LLAMA_HOME="./llama.cpp/build/bin"
export MODELS_DIR="./modelos"

# Aliases para uso rÃ¡pido
alias llama='$LLAMA_HOME/llama-cli -m $MODELS_DIR/general-model.gguf'
alias llama-code='$LLAMA_HOME/llama-cli -m $MODELS_DIR/code-model.gguf'
alias llama-creative='$LLAMA_HOME/llama-cli -m $MODELS_DIR/creative-model.gguf'

# Configuraciones predefinidas
alias quick-fix='llama -n 256 --temp 0.2 --repeat-penalty 1.1 --silent -p'
alias code-review='llama-code -c 8192 -n 1024 --temp 0.1 --silent -p'
alias brainstorm='llama-creative -c 4096 -n 800 --temp 0.9 --top-p 0.95 -p'
```

### Script de Benchmark Completo

```bash
#!/bin/bash
# Evaluar el rendimiento de todos tus modelos

benchmark_all() {
    local models_dir="$1"
    
    echo "ðŸ“Š BENCHMARK DE MODELOS"
    echo "======================"
    
    for model in "$models_dir"/*.gguf; do
        model_name=$(basename "$model" .gguf)
        echo "ðŸ§ª Evaluando: $model_name"
        
        ./llama-bench \
            -m "$model" \
            -p 512 \
            -n 128 \
            -t $(nproc) 2>/dev/null | \
            grep "llama_print_timings" || echo "âŒ Error en $model_name"
        echo ""
    done
    
    echo "âœ… Benchmark completado"
}

# Ejecutar benchmark
benchmark_all "./modelos"
```

---

## ðŸ“š Referencias TÃ©cnicas

### Formatos de CuantizaciÃ³n (Ordenados por Calidad/TamaÃ±o)

| Formato | Calidad | TamaÃ±o | Recomendado Para |
|---------|---------|--------|------------------|
| **Q8_0** | 99% | 50% del original | MÃ¡xima calidad, hardware potente |
| **Q6_K** | 98% | 60% del original | Equilibrio excelente |
| **Q5_K_M** | 95% | 70% del original | Uso general recomendado |
| **Q4_K_M** | 90% | 50% del original | Hardware limitado |
| **Q4_K_S** | 85% | 45% del original | MÃ¡xima compresiÃ³n Ãºtil |

### Comandos de DiagnÃ³stico

```bash
# Verificar integridad de modelo
./llama-gguf-hash -f modelo.gguf

# AnÃ¡lisis de tokenizaciÃ³n
./llama-tokenize -m modelo.gguf -p "Tu texto aquÃ­"

# Test rÃ¡pido de funcionalidad
./llama-cli -m modelo.gguf -p "2+2=" -n 5 --temp 0.1

# InformaciÃ³n del modelo
./llama-cli -m modelo.gguf --help | head -20
```

### PrÃ³ximos Pasos Recomendados

1. **Experimenta con temperaturas** para diferentes tipos de tareas
2. **Configura aliases** para tus workflows mÃ¡s comunes  
3. **Prueba el modo servidor** para integrar con otras aplicaciones
4. **Optimiza el contexto** segÃºn el tipo de documentos que procesas
5. **Automatiza la selecciÃ³n** de modelos segÃºn el contenido

---

> **Estructura tÃ­pica**: `./llama.cpp/build/bin/` (binarios) y `./modelos/` (archivos .gguf)
> 
> **InstalaciÃ³n**: Compilar llama.cpp desde el repositorio oficial de GitHub

Â¡Tienes todo lo necesario para dominar tu ecosistema de IA local!
