# llama.cpp å®Œå…¨æŒ‡å— - åœ¨ç»ˆç«¯ä¸­è¿è¡Œæœ¬åœ°AI

> æŒæ¡æœ¬åœ°AIæ¨¡å‹ç”Ÿæ€ç³»ç»Ÿçš„å®ç”¨æŒ‡å—

---

## ğŸ§  åŸºæœ¬æ¦‚å¿µï¼ˆä¸ºäº†æ­£ç¡®å¼€å§‹ï¼‰

### ä»€ä¹ˆæ˜¯ `.gguf` æ–‡ä»¶ï¼Ÿ

ç±»ä¼¼äºAIæ¨¡å‹çš„**ZIPæ–‡ä»¶**ã€‚åŒ…å«äº†æ‰€æœ‰å¿…è¦å…ƒç´ ï¼š
- æ¨¡å‹æ¶æ„ï¼ˆæ„å»ºæ–¹å¼ï¼‰
- ç¥ç»æƒé‡ï¼ˆè®­ç»ƒè·å¾—çš„â€œçŸ¥è¯†â€ï¼‰
- åˆ†è¯å™¨ï¼ˆå°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å­—çš„æ–¹æ³•ï¼‰
- å…ƒæ•°æ®å’Œé…ç½®

**ä¾¿æºçš„åŸå› **ï¼šåªéœ€å¤åˆ¶æ–‡ä»¶ï¼Œå³å¯è·å¾—å®Œæ•´çš„AIã€‚

### ä»€ä¹ˆæ˜¯é‡åŒ–ï¼Ÿ

æƒ³è±¡ä¸€ä¸‹å°†4Kç…§ç‰‡å‹ç¼©æˆJPEGï¼š
- **F16**ï¼šæœ€é«˜ç²¾åº¦ï¼Œæ¶ˆè€—å¤§é‡RAM
- **Q8_0**ï¼šå‡ ä¹æ— æŸï¼Œå‡å°‘50% RAMå ç”¨
- **Q6_K**ï¼šè´¨é‡ä¸å¤§å°çš„ç»ä½³å¹³è¡¡
- **Q5_K_M**ï¼šè‰¯å¥½è´¨é‡ï¼Œç´§å‡‘
- **Q4_K_M**ï¼šå¤§å¤šæ•°ç”¨é€”æ¨èçš„æ ‡å‡†
- **Q4_K_S**ï¼šéå¸¸ç´§å‡‘ï¼Œè´¨é‡ä¸‹é™æ˜æ˜¾ä½†ä»å®ç”¨

### ä»¤ç‰Œï¼šAIçš„â€œè´§å¸â€

æ¨¡å‹è¯»å–çš„æ˜¯**ä»¤ç‰Œ**è€Œéå•è¯ï¼š
- `"ã“ã‚“ã«ã¡ã¯"` = 3ä¸ªä»¤ç‰Œ
- `"äººå·¥"` = 2ä¸ªä»¤ç‰Œ
- `"ğŸ¤–"` = 1ä¸ªä»¤ç‰Œ

**ç»éªŒæ³•åˆ™**ï¼š1ä¸ªä»¤ç‰Œ â‰ˆ æ—¥è¯­ä¸­çº¦0.5ä¸ªå­—ç¬¦ã€‚

---

## ğŸ¯ æ¨¡å‹ç±»å‹ä¸ä¸“ä¸šé¢†åŸŸ

### æŒ‰è¯­è¨€å’Œé¢†åŸŸåˆ’åˆ†

| ä¸“ä¸šé¢†åŸŸ | ä¸»è¦è¯­è¨€ | é£æ ¼ | å…¸å‹ç”¨ä¾‹ |
|---------|---------|---------|-------------|
| **æŠ€æœ¯/å¾·è¯­** | å¾·è¯­ | æ­£å¼ã€è§„èŒƒ | å®˜æ–¹æ–‡ä»¶ã€ç²¾ç¡®ç¿»è¯‘ |
| **ç¼–ç¨‹** | è‹±è¯­ | ç»“æ„åŒ–åˆ†æ | è°ƒè¯•ã€æ¶æ„ã€ä»£ç å®¡æŸ¥ |
| **æ—¥è¯­** | æ—¥è¯­ | æŒ‡ä»¤æ€§ã€æŒ‡ç¤ºæ€§ | æ—¥è¯­æŠ€æœ¯æ–‡æ¡£ |
| **é•¿æ–‡æœ¬ä¸Šä¸‹æ–‡** | å¤šè¯­è¨€ | å¹¿æ³›çŸ¥è¯† | å¤æ‚åˆ†æã€ç ”ç©¶ |
| **é€šç”¨/å¹³è¡¡** | è‹±è¯­ | æµç•…ç”Ÿæˆ | æ—¥å¸¸ä½¿ç”¨ã€å„ç§ä»»åŠ¡ |
| **åŒ»ç–—/ä¸´åºŠ** | è‹±è¯­ | ä¸´åºŠã€ç”Ÿç‰©åŒ»å­¦ | åŒ»ç–—ã€è¯å­¦æ–‡æœ¬ |
| **å¯¹è¯** | è‹±è¯­ | è‡ªç„¶å¯¹è¯ | èŠå¤©ã€å®¢æˆ·æ”¯æŒ |
| **æ–‡æ¡£ç¼–å†™** | è‹±è¯­ | æ¸©å’Œè¯´æ˜ | æ‰‹å†Œã€æŠ€æœ¯æŒ‡å— |
| **ç´§å‡‘/é«˜é€Ÿ** | è‹±è¯­ | é«˜æ•ˆæ¨ç† | å¿«é€Ÿæµ‹è¯•ã€æœ‰é™ç¡¬ä»¶ |
| **å¤šè¯­è¨€** | ä¸­æ–‡/è‹±è¯­ | å¹¿æ³›ä¸Šä¸‹æ–‡ | å›½é™…æ–‡æ¡£ |
| **è¶…è½»é‡** | è‹±è¯­ | å¿«é€Ÿæµ‹è¯• | å¼€å‘ã€IoTã€å®éªŒ |
| **Pythonä¸“ç²¾** | è‹±è¯­ | è¯¦ç»†æ•™ç¨‹ | ç¼–ç¨‹æ•™è‚² |
| **å­¦æœ¯** | ä¸­æ–‡/è‹±è¯­ | ç§‘å­¦è®ºæ–‡ | ç ”ç©¶ã€æŠ€æœ¯æ–‡æœ¬ |
| **æ³•å¾‹/æ­£å¼** | è‹±è¯­ | åˆ¶åº¦æ€§ | åˆåŒã€æ”¿ç­–ã€åˆè§„ |
| **è‡ªåŠ¨åŒ–** | è‹±è¯­ | å¤æ‚åˆ¤æ–­ | å·¥ä½œæµã€æµç¨‹ç®¡ç† |
| **æ— è¿‡æ»¤åŸºç¡€** | è‹±è¯­ | ä¸­ç«‹ | å®éªŒã€ç›´æ¥å›ç­” |
| **æ•…äº‹** | è‹±è¯­ | ç¥è¯ã€å™äº‹ | ä¸–ç•Œæ„å»ºã€å™äº‹å°è¯´ |
| **å¯Œæœ‰è¡¨ç°åŠ›çš„åˆ›ä½œ** | è‹±è¯­ | æˆå‰§æ€§ã€æƒ…æ„Ÿä¸°å¯Œ | å°è¯´ã€åˆ›é€ æ€§è§’è‰²æ‰®æ¼” |
| **å“²å­¦** | è‹±è¯­ | è‹æ ¼æ‹‰åº•å¼å¯¹è¯ | è¾©è®ºã€æ‰¹åˆ¤æ€§æ€ç»´ |
| **æ— å®¡æŸ¥** | è‹±è¯­ | æ•æ„Ÿè¯é¢˜ | å®‰å…¨ç ”ç©¶ |
| **é«˜çº§è§’è‰²æ‰®æ¼”** | è‹±è¯­ | è‡ªç”±å½¢å¼æ•…äº‹ | è§’è‰²æ‰®æ¼”ã€åˆ›é€ æ€§æ¢ç´¢ |

---

## ğŸ›  ç”Ÿæ€ç³»ç»Ÿå·¥å…·

### 1. è¿è¡Œæ ¸å¿ƒ

| äºŒè¿›åˆ¶æ–‡ä»¶ | ä¸»è¦åŠŸèƒ½ | ä½¿ç”¨æ—¶æœº |
|---------|----------|---------|
| `llama-cli` | **ä¸»å¼•æ“**ã€‚ä»ç»ˆç«¯è¿è¡Œæ¨¡å‹ | è„šæœ¬ã€è‡ªåŠ¨åŒ–ã€å¿«é€Ÿæµ‹è¯• |
| `llama-run` | å¸¦å¯¹è¯è®°å¿†çš„äº¤äº’å¼èŠå¤© | å®éªŒã€ä¸æ¨¡å‹äº¤äº’ |
| `llama-server` | å¸¦REST APIçš„WebæœåŠ¡å™¨ | åº”ç”¨ç¨‹åºé›†æˆã€è¿œç¨‹ä½¿ç”¨ |

### 2. åˆ†æå·¥å…·

| å·¥å…· | åŠŸèƒ½ | å®ç”¨ä»·å€¼ |
|-------|------|---------------|
| `llama-tokenize` | æ˜¾ç¤ºæ¨¡å‹å¦‚ä½•è§£é‡Šæ–‡æœ¬ | æç¤ºä¼˜åŒ–ã€ç†è§£é™åˆ¶ |
| `llama-bench` | æµ‹é‡ç¡¬ä»¶æ€§èƒ½ | æ¨¡å‹æ¯”è¾ƒã€è®¾ç½®ä¼˜åŒ– |
| `llama-embedding` | å°†æ–‡æœ¬è½¬æ¢ä¸ºæ•°å€¼å‘é‡ | è¯­ä¹‰æœç´¢ã€ç›¸ä¼¼æ€§åˆ†æ |

### 3. ä¼˜åŒ–å·¥å…·

| å·¥å…· | ç›®çš„ | ä½•æ—¶éœ€è¦ |
|-------|------|----------|
| `llama-quantize` | å‹ç¼©æ¨¡å‹ä»¥å‡å°‘RAMä½¿ç”¨ | ç¡¬ä»¶æ— æ³•è¿è¡Œå®Œæ•´æ¨¡å‹ |
| `llama-gguf-split` | å°†æ¨¡å‹åˆ†å‰²æˆç‰‡æ®µ | ä¸‹è½½æ…¢ã€å­˜å‚¨é™åˆ¶ |
| `llama-gguf-hash` | éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ | ç¡®ä¿ä¸‹è½½æ­£ç¡® |

---

## âš™ï¸ é‡è¦å‚æ•°

### åŸºç¡€ï¼ˆå¿…éœ€ï¼‰

| å‚æ•° | åŠŸèƒ½ | å…¸å‹å€¼ | å®ä¾‹ |
|-----------|------|-----------|-------|
| `-m` | æ¨¡å‹è·¯å¾„ | ç»å¯¹è·¯å¾„ | `-m ~/models/mistral-7b.gguf` |
| `-p` | æç¤º/é—®é¢˜ | è‡ªç”±æ–‡æœ¬ | `-p "è§£é‡Šä¸€ä¸‹å…‰åˆä½œç”¨"` |
| `-n, --n-predict` | ç”Ÿæˆçš„æœ€å¤§ä»¤ç‰Œæ•° | 128-2048 | `-n 512` (ä¸­ç­‰é•¿åº¦å“åº”) |
| `-c, --ctx-size` | ä¸Šä¸‹æ–‡å¤§å° | 512-16384 | `-c 4096` (é•¿æ–‡æ¡£) |

### ä¸Šä¸‹æ–‡ä¸å†…å­˜æ§åˆ¶

| è®¾ç½® | ä¼°ç®—RAMä½¿ç”¨é‡ | ç†æƒ³åœºæ™¯ |
|------|-------------|----------------|
| `--ctx-size 1024` | ~1-2MB | åŸºæœ¬èŠå¤©ã€çŸ­é—®é¢˜ |
| `--ctx-size 2048` | ~2-4MB | å¸¸è§„å¯¹è¯ |
| `--ctx-size 4096` | ~4-8MB | ä¸­ç­‰æ–‡æ¡£ã€åˆ†æ |
| `--ctx-size 8192` | ~8-16MB | é•¿æ–‡æœ¬ã€ç ”ç©¶ |
| `--ctx-size 16384` | ~16-32MB | éå¸¸å¹¿æ³›çš„æ–‡æ¡£ |

### åˆ›é€ åŠ›æ§åˆ¶

| æ¸©åº¦ | è¡Œä¸º | ç”¨ä¾‹ |
|------|------|-------|
| `--temp 0.1` | **æœºå™¨äºº**ï¼šéå¸¸ç¡®å®šæ€§ | ä»£ç ã€ä¿®æ­£ã€ç²¾ç¡®æ•°æ® |
| `--temp 0.3` | **æŠ€æœ¯æ€§**ï¼šç²¾ç¡®ä½†çµæ´» | æ–‡æ¡£åŒ–ã€è§£é‡Š |
| `--temp 0.7` | **äººæ€§åŒ–**ï¼šè‡ªç„¶å¹³è¡¡ | ä¸€èˆ¬å¯¹è¯ |
| `--temp 0.9` | **åˆ›é€ æ€§**ï¼šåŠ¨æ€ | å¤´è„‘é£æš´ã€åˆ›æ„ |
| `--temp 1.2` | **è‰ºæœ¯å®¶**ï¼šéå¸¸å®éªŒæ€§ | å°è¯´ã€è‡ªç”±å½¢å¼æ•…äº‹ |

### è¾“å‡ºè´¨é‡æ§åˆ¶

| å‚æ•° | æ•ˆæœ | ä¿å®ˆå€¼ | åˆ›é€ å€¼ |
|-----------|------|-----------|-----------|
| `--top-p` | è¯æ±‡å¤šæ ·æ€§ | 0.9 | 0.95 |
| `--top-k` | ä»¤ç‰Œé€‰æ‹©é™åˆ¶ | 20-40 | 80-100 |
| `--repeat-penalty` | é˜²æ­¢é‡å¤ | 1.1 | 1.05 |
| `--repeat-last-n` | é˜²é‡å¤çª—å£ | 64 | 128 |

### æ€§èƒ½ä¼˜åŒ–

| å‚æ•° | åŠŸèƒ½ | å…¸å‹è®¾ç½® |
|-----------|------|-------------|
| `-t, --threads` | CPUçº¿ç¨‹æ•° | å¯ç”¨æ ¸å¿ƒæ•° |
| `--batch-size` | æ‰¹å¤„ç† | 512-2048ï¼ˆå–å†³äºRAMï¼‰ |
| `--gpu-layers` | GPUä¸Šçš„å±‚æ•° | 99ï¼ˆä½¿ç”¨å…¨éƒ¨GPUï¼‰ |

---

## ğŸ“‹ æŒ‰ä¸“ä¸šé¢†åŸŸåˆ’åˆ†çš„é…æ–¹

### ğŸ”§ æ–‡æœ¬ä¿®æ­£ä¸ç¼–è¾‘

```bash
# ç²¾å¯†æ–‡æ¡£ä¿®æ­£
./llama-cli \
    -m ./models/mistral-7b-instruct.gguf \
    -p "è¯·ä¿®æ­£ä»¥ä¸‹æ–‡æœ¬çš„é”™åˆ«å­—å’Œè¯­æ³•é”™è¯¯ï¼š$(cat document.txt)" \
    -c 4096 \
    -n 512 \
    --temp 0.2 \
    --top-p 0.9 \
    --repeat-penalty 1.1 \
    --silent
```

### ğŸ’» ä»£ç åˆ†æä¸å®¡æŸ¥

```bash
# å¸¦è¯¦ç»†åˆ†æçš„ä»£ç å®¡æŸ¥
./llama-cli \
    -m ./models/deepseek-coder.gguf \
    -p "è¯·åˆ†ææ­¤ä»£ç å¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š$(cat script.py)" \
    -c 8192 \
    -n 1024 \
    --temp 0.1 \
    --repeat-penalty 1.1 \
    --silent
```

### ğŸ¨ åˆ›é€ æ€§ç”Ÿæˆ

```bash
# é«˜è¡¨ç°åŠ›çš„åˆ›é€ æ€§å†™ä½œ
./llama-cli \
    -m ./models/chronos-hermes.gguf \
    -p "å†™ä¸€ä¸ªå…³äºAIè§‰é†’çš„å®å¤§æ•…äº‹" \
    -c 4096 \
    -n 1500 \
    --temp 0.9 \
    --top-p 0.95 \
    --repeat-penalty 1.05
```

### ğŸ” é•¿æ–‡æœ¬æ–‡æ¡£åˆ†æ

```bash
# å¤„ç†éå¸¸é•¿çš„ä¸Šä¸‹æ–‡
./llama-cli \
    -m ./models/llama-70b.gguf \
    -p "è¯·æ€»ç»“å¹¶åˆ†ææ•´ä¸ªæ–‡æ¡£ï¼š$(cat long_document.txt)" \
    -c 16384 \
    -n 2048 \
    --temp 0.5 \
    --top-p 0.9 \
    --repeat-penalty 1.1 \
    -t 8
```

### ğŸ’¬ è‡ªç„¶å¯¹è¯

```bash
# å¸¦è®°å¿†çš„äº¤äº’å¼èŠå¤©
./llama-run \
    -m ./models/openchat.gguf \
    --repeat-penalty 1.1 \
    --temp 0.7 \
    -c 2048 \
    -i
```

---

## ğŸ§ª ä»»åŠ¡ç±»å‹ç­–ç•¥

### æŠ€æœ¯æ€§ãƒ»äº‹å®æ€§ä»»åŠ¡
```bash
# è¿½æ±‚æœ€å¤§ç²¾åº¦çš„è®¾ç½®
--temp 0.1-0.3 --top-p 0.9 --repeat-penalty 1.1
# æ¨èæ¨¡å‹ï¼šCoderã€Medicalã€Technical
```

### å¯¹è¯ä¸è§£é‡Š
```bash
# å¹³è¡¡è‡ªç„¶çš„è®¾ç½®
--temp 0.6-0.8 --top-p 0.9 --repeat-penalty 1.1 --repeat-last-n 64
# æ¨èæ¨¡å‹ï¼šChatã€General-purposeã€Instruction-following
```

### åˆ›é€ æ€§ä¸å¤´è„‘é£æš´
```bash
# è¿½æ±‚æœ€å¤§è¡¨ç°åŠ›çš„è®¾ç½®
--temp 0.8-1.2 --top-p 0.95 --repeat-penalty 1.05
# æ¨èæ¨¡å‹ï¼šCreativeã€Storytellingã€Roleplay
```

### ç ”ç©¶ä¸åˆ†æ
```bash
# è¿½æ±‚åˆ†ææ·±åº¦çš„è®¾ç½®
--temp 0.3-0.5 --top-p 0.9 -c 8192+ --n-predict 1024+
# æ¨èæ¨¡å‹ï¼šLarge contextã€Academicã€Research-focused
```

---

## ğŸš€ è‡ªåŠ¨åŒ–ä¸é›†æˆ

### è‡ªåŠ¨æ¨¡å‹é€‰æ‹©è„šæœ¬

```bash
#!/bin/bash
# åŸºäºä»»åŠ¡ç±»å‹çš„æ™ºèƒ½é€‰æ‹©å™¨

select_model_by_task() {
    local task="$1"
    local base_path="./models"
    
    case "$task" in
        "code"|"programming")
            echo "$base_path/deepseek-coder.gguf"
            ;;
        "creative"|"story")
            echo "$base_path/chronos-hermes.gguf"
            ;;
        "medical"|"health")
            echo "$base_path/meditron.gguf"
            ;;
        "legal"|"formal")
            echo "$base_path/nous-hermes-legal.gguf"
            ;;
        "research"|"academic")
            echo "$base_path/llama-70b.gguf"
            ;;
        *)
            echo "$base_path/mistral-instruct.gguf"
            ;;
    esac
}

# ä½¿ç”¨é€‰æ‹©å™¨
TASK_TYPE="$1"
MODEL=$(select_model_by_task "$TASK_TYPE")
PROMPT="$2"

./llama-cli -m "$MODEL" -p "$PROMPT" -c 4096 -n 512 --temp 0.7
```

### å¤šæ¨¡å‹æœåŠ¡å™¨

```bash
#!/bin/bash
# å°†å¤šä¸ªæ¨¡å‹ä½œä¸ºæœåŠ¡å¯åŠ¨

start_model_server() {
    local model_path="$1"
    local port="$2"
    local model_name="$3"
    
    ./llama-server \
        -m "$model_path" \
        --host 0.0.0.0 \
        --port "$port" \
        -c 4096 \
        --gpu-layers 99 &
    
    echo "âœ… $model_name æœåŠ¡å™¨å·²åœ¨ç«¯å£ $port å¯åŠ¨"
}

# å¯åŠ¨ä¸“ä¸šæœåŠ¡
start_model_server "./models/mistral-general.gguf" 8080 "é€šç”¨"
start_model_server "./models/deepseek-coder.gguf" 8081 "ä»£ç "
start_model_server "./models/creative-model.gguf" 8082 "åˆ›é€ æ€§"

echo "ğŸŒ å¯ç”¨æœåŠ¡å™¨ï¼š"
echo "  é€šç”¨ï¼š http://localhost:8080"
echo "  ä»£ç ï¼š http://localhost:8081"
echo "  åˆ›é€ æ€§ï¼š http://localhost:8082"
```

### æ–‡æ¡£å¤„ç†ç®¡é“

```bash
#!/bin/bash
# å®Œæ•´ç®¡é“ï¼šOCR â†’ ä¿®æ­£ â†’ åˆ†æ

process_document() {
    local input_image="$1"
    local output_dir="./processed"
    
    mkdir -p "$output_dir"
    
    # 1. æ–‡æ¡£OCR
    tesseract "$input_image" "$output_dir/raw_text"
    
    # 2. AIä¿®æ­£
    ./llama-cli \
        -m ./models/correction-model.gguf \
        -p "è¯·ä¿®æ­£æ­¤æ–‡æœ¬ä¸­çš„é”™è¯¯ï¼š$(cat "$output_dir/raw_text.txt")" \
        -c 4096 -n 1024 --temp 0.2 --silent \
        > "$output_dir/corrected_text.txt"
    
    # 3. åˆ†æä¸æ‘˜è¦
    ./llama-cli \
        -m ./models/analysis-model.gguf \
        -p "è¯·æ€»ç»“å…³é”®ç‚¹ï¼š$(cat "$output_dir/corrected_text.txt")" \
        -c 2048 -n 256 --temp 0.5 --silent \
        > "$output_dir/summary.txt"
    
    echo "âœ… æ–‡æ¡£å·²åœ¨ $output_dir å¤„ç†å®Œæ¯•"
}

# ä½¿ç”¨ç®¡é“
process_document "scanned_document.png"
```

---

## ğŸ›¡ å¸¸è§æ•…éšœæ’é™¤

### éå¸¸å¤§çš„æ¨¡å‹ï¼ˆ70B+ï¼‰
**ç—‡çŠ¶**ï¼šç³»ç»Ÿç¼“æ…¢ã€å†…å­˜ä¸è¶³
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°‘å†…å­˜ä½¿ç”¨
-c 2048              # æ›´å°‘çš„ä¸Šä¸‹æ–‡
-t 4                 # æ›´å°‘çš„çº¿ç¨‹
--gpu-layers 50      # ä»…éƒ¨åˆ†GPUå¸è½½
# æˆ–è€…ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„é‡åŒ–ï¼ˆQ4_K_Sï¼‰
```

### ä»£ç æ¨¡å‹
**ç—‡çŠ¶**ï¼šå“åº”ä¸å®Œæ•´ã€ä»£ç è¢«æˆªæ–­
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
-n 2048              # æ›´å¤šçš„è¾“å‡ºä»¤ç‰Œ
--temp 0.1           # æœ€å¤§ç²¾åº¦
-c 8192              # ä¸ºé•¿ä»£ç æä¾›æ›´å¤šä¸Šä¸‹æ–‡
--ignore-eos         # ä¸æå‰åœæ­¢
```

### åˆ›é€ æ€§æ¨¡å‹
**ç—‡çŠ¶**ï¼šé‡å¤ã€ç¼ºä¹ä¸€è‡´æ€§
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
--repeat-penalty 1.1  # å¯¹é‡å¤æ–½åŠ æƒ©ç½š
--mirostat 2          # è‡ªåŠ¨æ§åˆ¶
--temp 0.8            # æ¸©åº¦ä¸è¦è®¾ç½®è¿‡é«˜
-c 4096+              # ä¸ºä¸€è‡´æ€§æä¾›æ›´å¤šä¸Šä¸‹æ–‡
```

### æ£€æµ‹æ€§èƒ½é—®é¢˜
```bash
# ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ
watch -n 1 'ps aux | grep llama-cli'

# å¿«é€ŸåŸºå‡†æµ‹è¯•
./llama-bench -m model.gguf -p 512 -n 128

# å†…å­˜æµ‹è¯•
./llama-cli -m model.gguf -c 1024 -n 10 --temp 0.1 -p "æµ‹è¯•"
```

---

## ğŸ¯ é«˜æ•ˆç”Ÿäº§è®¾ç½®

### æœ‰ç”¨çš„ç¯å¢ƒå˜é‡

```bash
# æ·»åŠ åˆ° .bashrc æˆ– .zshrc
export LLAMA_HOME="./llama.cpp/build/bin"
export MODELS_DIR="./models"

# ç”¨äºå¿«é€Ÿä½¿ç”¨çš„åˆ«å
alias llama='$LLAMA_HOME/llama-cli -m $MODELS_DIR/general-model.gguf'
alias llama-code='$LLAMA_HOME/llama-cli -m $MODELS_DIR/code-model.gguf'
alias llama-creative='$LLAMA_HOME/llama-cli -m $MODELS_DIR/creative-model.gguf'

# é¢„å®šä¹‰è®¾ç½®
alias quick-fix='llama -n 256 --temp 0.2 --repeat-penalty 1.1 --silent -p'
alias code-review='llama-code -c 8192 -n 1024 --temp 0.1 --silent -p'
alias brainstorm='llama-creative -c 4096 -n 800 --temp 0.9 --top-p 0.95 -p'
```

### å®Œæ•´åŸºå‡†æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# è¯„ä¼°æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½

benchmark_all() {
    local models_dir="$1"
    
    echo "ğŸ“Š æ¨¡å‹åŸºå‡†æµ‹è¯•"
    echo "======================"
    
    for model in "$models_dir"/*.gguf; do
        model_name=$(basename "$model" .gguf)
        echo "ğŸ§ª æ­£åœ¨è¯„ä¼°ï¼š $model_name"
        
        ./llama-bench \
            -m "$model" \
            -p 512 \
            -n 128 \
            -t $(nproc) 2>/dev/null | \
            grep "llama_print_timings" || echo "âŒ $model_name å‡ºé”™"
        echo ""
    done
    
    echo "âœ… åŸºå‡†æµ‹è¯•å®Œæˆ"
}

# è¿è¡ŒåŸºå‡†æµ‹è¯•
benchmark_all "./models"
```

---

## ğŸ“š æŠ€æœ¯å‚è€ƒ

### é‡åŒ–æ ¼å¼ï¼ˆæŒ‰è´¨é‡/å¤§å°æ’åºï¼‰

| æ ¼å¼ | è´¨é‡ | å¤§å° | æ¨èç”¨é€” |
|------|------|--------|---------|
| **Q8_0** | 99% | åŸå§‹çš„50% | æœ€é«˜è´¨é‡ã€å¼ºå¤§ç¡¬ä»¶ |
| **Q6_K** | 98% | åŸå§‹çš„60% | ä¼˜å¼‚å¹³è¡¡ |
| **Q5_K_M** | 95% | åŸå§‹çš„70% | æ¨èé€šç”¨ç”¨é€” |
| **Q4_K_M** | 90% | åŸå§‹çš„50% | æœ‰é™ç¡¬ä»¶ |
| **Q4_K_S** | 85% | åŸå§‹çš„45% | æœ€å¤§å®ç”¨å‹ç¼© |

### è¯Šæ–­å‘½ä»¤

```bash
# éªŒè¯æ¨¡å‹å®Œæ•´æ€§
./llama-gguf-hash -f model.gguf

# åˆ†è¯åˆ†æ
./llama-tokenize -m model.gguf -p "åœ¨æ­¤è¾“å…¥æ‚¨çš„æ–‡æœ¬"

# å¿«é€ŸåŠŸèƒ½æµ‹è¯•
./llama-cli -m model.gguf -p "2+2=" -n 5 --temp 0.1

# æ¨¡å‹ä¿¡æ¯
./llama-cli -m model.gguf --help | head -20
```

### æ¨èåç»­æ­¥éª¤

1.  åœ¨ä¸åŒä»»åŠ¡ç±»å‹ä¸Šè¯•éªŒæ¸©åº¦
2.  ä¸ºæœ€å¸¸è§çš„å·¥ä½œæµè®¾ç½®åˆ«å
3.  å°è¯•æœåŠ¡å™¨æ¨¡å¼ä»¥ä¸å…¶ä»–åº”ç”¨ç¨‹åºé›†æˆ
4.  æ ¹æ®å¤„ç†çš„æ–‡æ¡£ä¼˜åŒ–ä¸Šä¸‹æ–‡å¤§å°
5.  åŸºäºå†…å®¹å®ç°è‡ªåŠ¨æ¨¡å‹é€‰æ‹©

---

> **å…¸å‹ç»“æ„**ï¼š`./llama.cpp/build/bin/`ï¼ˆäºŒè¿›åˆ¶æ–‡ä»¶ï¼‰å’Œ `./models/`ï¼ˆ.ggufæ–‡ä»¶ï¼‰
>
> **å®‰è£…**ï¼šä»å®˜æ–¹GitHubä»“åº“ç¼–è¯‘llama.cpp

æŒæ¡æœ¬åœ°AIç”Ÿæ€ç³»ç»Ÿæ‰€éœ€çš„ä¸€åˆ‡éƒ½å·²å…·å¤‡ï¼

**Eto Demerzel** (Gustavo Silva Da Costa)
https://etodemerzel.gumroad.com  
https://github.com/BiblioGalactic
